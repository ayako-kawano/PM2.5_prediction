{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAQ data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing c:\\users\\ayako\\appdata\\local\\pip\\cache\\wheels\\0b\\12\\c0\\b52afbb4093f67c02dac5869ef6bad845a234e2bd76bd803e9\\ee-0.2-py3-none-any.whl\n",
      "Collecting blessings\n",
      "  Using cached blessings-1.7-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: six in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from blessings->ee) (1.15.0)\n",
      "Installing collected packages: blessings, ee\n",
      "Successfully installed blessings-1.7 ee-0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting windows-curses\n",
      "  Using cached windows_curses-2.2.0-cp38-cp38-win_amd64.whl (88 kB)\n",
      "Installing collected packages: windows-curses\n",
      "Successfully installed windows-curses-2.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install windows-curses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-api-python-client\n",
      "  Downloading google_api_python_client-2.1.0-py2.py3-none-any.whl (6.6 MB)\n",
      "Requirement already satisfied: six<2dev,>=1.13.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-python-client) (1.15.0)\n",
      "Collecting google-auth<2dev,>=1.16.0\n",
      "  Downloading google_auth-1.28.0-py2.py3-none-any.whl (136 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Downloading httplib2-0.19.1-py3-none-any.whl (95 kB)\n",
      "Collecting uritemplate<4dev,>=3.0.0\n",
      "  Using cached uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core<2dev,>=1.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.  Downloading google_api_core-1.26.3-py2.py3-none-any.whl (93 kB)\n",
      "\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-auth<2dev,>=1.16.0->google-api-python-client) (50.3.1.post20201107)\n",
      "Collecting cachetools<5.0,>=2.0.0\n",
      "  Using cached cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client) (2.4.7)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2.24.0)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.6.0\n",
      "  Downloading googleapis_common_protos-1.53.0-py2.py3-none-any.whl (198 kB)\n",
      "Requirement already satisfied: pytz in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (2020.1)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client) (20.4)\n",
      "Collecting protobuf>=3.12.0\n",
      "  Downloading protobuf-3.15.6-py2.py3-none-any.whl (173 kB)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client) (3.0.4)\n",
      "Installing collected packages: cachetools, pyasn1, pyasn1-modules, rsa, google-auth, httplib2, uritemplate, google-auth-httplib2, protobuf, googleapis-common-protos, google-api-core, google-api-python-client\n",
      "Successfully installed cachetools-4.2.1 google-api-core-1.26.3 google-api-python-client-2.1.0 google-auth-1.28.0 google-auth-httplib2-0.1.0 googleapis-common-protos-1.53.0 httplib2-0.19.1 protobuf-3.15.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.7.2 uritemplate-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting earthengine-api\n",
      "  Downloading earthengine-api-0.1.259.tar.gz (150 kB)\n",
      "Requirement already satisfied: future in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from earthengine-api) (0.18.2)\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-1.37.0-py2.py3-none-any.whl (103 kB)\n",
      "Collecting google-api-python-client<2,>=1.12.1\n",
      "  Using cached google_api_python_client-1.12.8-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: google-auth>=1.4.1 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from earthengine-api) (1.28.0)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from earthengine-api) (0.1.0)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.9.2 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from earthengine-api) (0.19.1)\n",
      "Processing c:\\users\\ayako\\appdata\\local\\pip\\cache\\wheels\\04\\5d\\b9\\a746c136fae5811cb2d30d8112b0f72ba40e24d22885bbe7c7\\httplib2shim-0.0.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: six in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from earthengine-api) (1.15.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-cloud-storage->earthengine-api) (2.24.0)\n",
      "Collecting google-cloud-core<2.0dev,>=1.4.1\n",
      "  Using cached google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
      "Collecting google-resumable-media<2.0dev,>=1.2.0\n",
      "  Using cached google_resumable_media-1.2.0-py2.py3-none-any.whl (75 kB)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-python-client<2,>=1.12.1->earthengine-api) (1.26.3)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-python-client<2,>=1.12.1->earthengine-api) (3.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api) (4.2.1)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api) (50.3.1.post20201107)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-auth>=1.4.1->earthengine-api) (4.7.2)\n",
      "Requirement already satisfied: pyparsing<3,>=2.4.2 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from httplib2<1dev,>=0.9.2->earthengine-api) (2.4.7)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from httplib2shim->earthengine-api) (1.25.11)\n",
      "Requirement already satisfied: certifi in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from httplib2shim->earthengine-api) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->earthengine-api) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage->earthengine-api) (3.0.4)\n",
      "Collecting google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"\n",
      "  Using cached google_crc32c-1.1.2-cp38-cp38-win_amd64.whl (34 kB)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (3.15.6)\n",
      "Requirement already satisfied: packaging>=14.3 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (20.4)\n",
      "Requirement already satisfied: pytz in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client<2,>=1.12.1->earthengine-api) (2020.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.4.1->earthengine-api) (0.4.8)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->earthengine-api) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ayako\\anaconda3\\lib\\site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=1.2.0->google-cloud-storage->earthengine-api) (2.20)\n",
      "Building wheels for collected packages: earthengine-api\n",
      "  Building wheel for earthengine-api (setup.py): started\n",
      "  Building wheel for earthengine-api (setup.py): finished with status 'done'\n",
      "  Created wheel for earthengine-api: filename=earthengine_api-0.1.259-py3-none-any.whl size=178440 sha256=1681a616786113ce50032cca5df4cff638e8e6b75281314ac556035d19c589ec\n",
      "  Stored in directory: c:\\users\\ayako\\appdata\\local\\pip\\cache\\wheels\\80\\f5\\85\\7114145ab1527a91247f9b9e65b20516905a2ae44fb35fe9c3\n",
      "Successfully built earthengine-api\n",
      "Installing collected packages: google-cloud-core, google-crc32c, google-resumable-media, google-cloud-storage, google-api-python-client, httplib2shim, earthengine-api\n",
      "  Attempting uninstall: google-api-python-client\n",
      "    Found existing installation: google-api-python-client 2.1.0\n",
      "    Uninstalling google-api-python-client-2.1.0:\n",
      "      Successfully uninstalled google-api-python-client-2.1.0\n",
      "Successfully installed earthengine-api-0.1.259 google-api-python-client-1.12.8 google-cloud-core-1.6.0 google-cloud-storage-1.37.0 google-crc32c-1.1.2 google-resumable-media-1.2.0 httplib2shim-0.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install earthengine-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ee\n",
    "from tqdm import tqdm # Progress bar\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>To authorize access needed by Earth Engine, open the following\n",
       "        URL in a web browser and follow the instructions:</p>\n",
       "        <p><a href=https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=JbJ_sfEOlD6YyQfOQk0i_zrpspMwJET0ukp39FYd-KQ&code_challenge_method=S256>https://accounts.google.com/o/oauth2/auth?client_id=517222506229-vsmmajv00ul0bs7p89v5m89qs8eb9359.apps.googleusercontent.com&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fearthengine+https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdevstorage.full_control&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&code_challenge=JbJ_sfEOlD6YyQfOQk0i_zrpspMwJET0ukp39FYd-KQ&code_challenge_method=S256</a></p>\n",
       "        <p>The authorization workflow will generate a code, which you\n",
       "        should paste in the box below</p>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter verification code: 4/1AY0e-g6mEyWvsyk7GuZeMv4vyLQoddowd8RYAmXo4JVl1QXIVdLcFDgkD4g\n",
      "\n",
      "Successfully saved authorization token.\n"
     ]
    }
   ],
   "source": [
    "ee.Authenticate()  # Run once to link your Google Earth Engine account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize() # Run each session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>parameter</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>date.utc</th>\n",
       "      <th>coordinates.latitude</th>\n",
       "      <th>coordinates.longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2260301</th>\n",
       "      <td>SAB-RAME - Sabaneta - I.E. Rafael J. Mejía</td>\n",
       "      <td>pm25</td>\n",
       "      <td>9.53084</td>\n",
       "      <td>b'\\xc2\\xb5g/m\\xc2\\xb3'</td>\n",
       "      <td>CO</td>\n",
       "      <td>Sabaneta</td>\n",
       "      <td>2020-06-22 13:00:00+00:00</td>\n",
       "      <td>6.145500</td>\n",
       "      <td>-75.621262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2111363</th>\n",
       "      <td>CAL-JOAR - Caldas - E U Joaquín Aristizabal</td>\n",
       "      <td>pm25</td>\n",
       "      <td>22.76360</td>\n",
       "      <td>b'\\xc2\\xb5g/m\\xc2\\xb3'</td>\n",
       "      <td>CO</td>\n",
       "      <td>Caldas</td>\n",
       "      <td>2020-10-17 11:00:00+00:00</td>\n",
       "      <td>6.093078</td>\n",
       "      <td>-75.637764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741005</th>\n",
       "      <td>Jadavpur, Kolkata - WBPCB</td>\n",
       "      <td>pm25</td>\n",
       "      <td>69.70000</td>\n",
       "      <td>b'\\xc2\\xb5g/m\\xc2\\xb3'</td>\n",
       "      <td>IN</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>2020-03-18 09:15:00+00:00</td>\n",
       "      <td>22.499290</td>\n",
       "      <td>88.369170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479551</th>\n",
       "      <td>Karachi</td>\n",
       "      <td>pm25</td>\n",
       "      <td>25.30000</td>\n",
       "      <td>b'\\xc2\\xb5g/m\\xc2\\xb3'</td>\n",
       "      <td>PK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-28 14:00:00+00:00</td>\n",
       "      <td>24.841500</td>\n",
       "      <td>67.009100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2101201</th>\n",
       "      <td>US Diplomatic Post: Bogota</td>\n",
       "      <td>pm25</td>\n",
       "      <td>16.00000</td>\n",
       "      <td>b'\\xc2\\xb5g/m\\xc2\\xb3'</td>\n",
       "      <td>CO</td>\n",
       "      <td>Bogota</td>\n",
       "      <td>2020-11-16 20:00:00+00:00</td>\n",
       "      <td>4.637735</td>\n",
       "      <td>-74.094860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            location parameter     value  \\\n",
       "2260301   SAB-RAME - Sabaneta - I.E. Rafael J. Mejía      pm25   9.53084   \n",
       "2111363  CAL-JOAR - Caldas - E U Joaquín Aristizabal      pm25  22.76360   \n",
       "741005                     Jadavpur, Kolkata - WBPCB      pm25  69.70000   \n",
       "1479551                                      Karachi      pm25  25.30000   \n",
       "2101201                   US Diplomatic Post: Bogota      pm25  16.00000   \n",
       "\n",
       "                           unit country      city                   date.utc  \\\n",
       "2260301  b'\\xc2\\xb5g/m\\xc2\\xb3'      CO  Sabaneta  2020-06-22 13:00:00+00:00   \n",
       "2111363  b'\\xc2\\xb5g/m\\xc2\\xb3'      CO    Caldas  2020-10-17 11:00:00+00:00   \n",
       "741005   b'\\xc2\\xb5g/m\\xc2\\xb3'      IN   Kolkata  2020-03-18 09:15:00+00:00   \n",
       "1479551  b'\\xc2\\xb5g/m\\xc2\\xb3'      PK       NaN  2020-01-28 14:00:00+00:00   \n",
       "2101201  b'\\xc2\\xb5g/m\\xc2\\xb3'      CO    Bogota  2020-11-16 20:00:00+00:00   \n",
       "\n",
       "         coordinates.latitude  coordinates.longitude  \n",
       "2260301              6.145500             -75.621262  \n",
       "2111363              6.093078             -75.637764  \n",
       "741005              22.499290              88.369170  \n",
       "1479551             24.841500              67.009100  \n",
       "2101201              4.637735             -74.094860  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/02_OpenAQ/world_openaq.csv')\n",
    "world.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = world.rename(columns={\"date.utc\": \"Date\", \"coordinates.latitude\": \"Lat\", \"coordinates.longitude\":\"Long\", \"value\": \"PM25\"})\n",
    "world['Date'] = world['Date'].astype(str).str[:10]\n",
    "world = world.drop(columns=['unit', 'parameter'], axis =1)\n",
    "world = world[['location', 'Date', 'city', 'country', 'PM25', 'Lat','Long']]\n",
    "world['PM25'] = world.groupby(['Date','location'])['PM25'].transform(lambda x: x.mean())\n",
    "world = world.groupby(['Date', 'location']).first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96195, 7)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Data from Google Earth Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population density, night light data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'avg_vis': 8.628110885620117, 'cf_cvg': 84}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A utility function to pull data for a set of locations\n",
    "def sample(im, prop, lats, lons, scale=100, reducer=ee.Reducer.first(), tileScale=4):\n",
    "    points = []\n",
    "    for lat, lon in zip(lats, lons):\n",
    "        xy = ee.Geometry.Point([lon, lat])\n",
    "        points.append(xy.buffer(scale))\n",
    "    vals = im.reduceRegions(collection=ee.FeatureCollection(points), scale=scale, reducer=reducer, tileScale=tileScale).getInfo()\n",
    "    if prop == '':\n",
    "        return [v['properties'] for v in vals['features']]\n",
    "    return [v['properties'][prop] for v in vals['features']]\n",
    "\n",
    "# Example:\n",
    "lights = ee.ImageCollection(\"NOAA/DMSP-OLS/CALIBRATED_LIGHTS_V4\") # An image collection\n",
    "lights = lights.filter(ee.Filter.date('2010-01-01', '2018-03-08')).first() # An image\n",
    "vals = sample(lights, '', [-18.136], [30.15], scale=100) # See image value for a single location\n",
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#population data\n",
    "def add_static_vars(df, scale = 2000):\n",
    "    lights = ee.ImageCollection(\"NOAA/DMSP-OLS/CALIBRATED_LIGHTS_V4\").filter(ee.Filter.date('2010-01-01', '2018-03-08')).first()\n",
    "    pop = ee.ImageCollection(\"CIESIN/GPWv411/GPW_UNWPP-Adjusted_Population_Density\").filter(ee.Filter.date('2010-01-01', '2018-03-08')).first()\n",
    "    ims = [lights, pop]\n",
    "\n",
    "    for im in tqdm(ims):\n",
    "        for i, reducer in enumerate([ee.Reducer.mean(), ee.Reducer.min(), ee.Reducer.max()]):\n",
    "            sampled_values = sample(im, '', df['Lat'].values, df['Long'].values, reducer=reducer)\n",
    "            for k in sampled_values[0].keys():\n",
    "                arr = ['mean', 'min', 'max']\n",
    "                df[k+'_'+ arr[i]] = [sv[k] if k in sv.keys() else None for sv in sampled_values]\n",
    "                if k == arr[i]:\n",
    "                    df = df.rename(columns={k+'_'+ arr[i]:'pop_density2010'+'_'+ arr[i]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = world.groupby('location').first().reset_index() # The locations to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(463, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:23<00:00, 11.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add static vars\n",
    "locations_w_static = add_static_vars(locations.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_w_static = locations_w_static.drop(columns=['Date', 'PM25', 'Lat', 'Long', 'city','country'], axis=1)\n",
    "world_w_static = pd.merge(world, locations_w_static, on='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>location</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>PM25</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Long</th>\n",
       "      <th>avg_vis_mean</th>\n",
       "      <th>cf_cvg_mean</th>\n",
       "      <th>avg_vis_min</th>\n",
       "      <th>cf_cvg_min</th>\n",
       "      <th>avg_vis_max</th>\n",
       "      <th>cf_cvg_max</th>\n",
       "      <th>pop_density2010_mean</th>\n",
       "      <th>pop_density2010_min</th>\n",
       "      <th>pop_density2010_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>34.095238</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-23</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>33.347826</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-24</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>41.625000</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>29.904762</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-26</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>DISTRITO FEDERAL</td>\n",
       "      <td>MX</td>\n",
       "      <td>30.833333</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>15686.94043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   location              city country       PM25      Lat  \\\n",
       "0  2018-11-22  Camarones  DISTRITO FEDERAL      MX  34.095238  19.4684   \n",
       "1  2018-11-23  Camarones  DISTRITO FEDERAL      MX  33.347826  19.4684   \n",
       "2  2018-11-24  Camarones  DISTRITO FEDERAL      MX  41.625000  19.4684   \n",
       "3  2018-11-25  Camarones  DISTRITO FEDERAL      MX  29.904762  19.4684   \n",
       "4  2018-11-26  Camarones  DISTRITO FEDERAL      MX  30.833333  19.4684   \n",
       "\n",
       "      Long  avg_vis_mean  cf_cvg_mean  avg_vis_min  cf_cvg_min  avg_vis_max  \\\n",
       "0 -99.1697    577.686646          9.0   577.686646         9.0   577.686646   \n",
       "1 -99.1697    577.686646          9.0   577.686646         9.0   577.686646   \n",
       "2 -99.1697    577.686646          9.0   577.686646         9.0   577.686646   \n",
       "3 -99.1697    577.686646          9.0   577.686646         9.0   577.686646   \n",
       "4 -99.1697    577.686646          9.0   577.686646         9.0   577.686646   \n",
       "\n",
       "   cf_cvg_max  pop_density2010_mean  pop_density2010_min  pop_density2010_max  \n",
       "0         9.0           15686.94043          15686.94043          15686.94043  \n",
       "1         9.0           15686.94043          15686.94043          15686.94043  \n",
       "2         9.0           15686.94043          15686.94043          15686.94043  \n",
       "3         9.0           15686.94043          15686.94043          15686.94043  \n",
       "4         9.0           15686.94043          15686.94043          15686.94043  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_w_static.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries data (Sentinel-5P, weather data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#timeseries data\n",
    "# Image Collections\n",
    "gfs = ee.ImageCollection(\"NOAA/GFS0P25\") # Weather data\n",
    "\n",
    "S5p_collections = {} # Sentinel 5p data, which comes in multiple collections\n",
    "for COL in ['L3_NO2', 'L3_O3', 'L3_CO', 'L3_AER_AI']: # \n",
    "    S5p_collections[COL] = ee.ImageCollection('COPERNICUS/S5P/OFFL/'+COL).map(lambda image: image.addBands\\\n",
    "                                                                              (image.metadata('system:time_start')))\n",
    "# Properties for each image we want to keep\n",
    "s5p_props = {\n",
    "    'L3_NO2':['NO2_column_number_density', 'tropospheric_NO2_column_number_density', 'stratospheric_NO2_column_number_density',\\\n",
    "              'NO2_slant_column_number_density', 'tropopause_pressure'],\n",
    "    'L3_O3':['O3_column_number_density'],\n",
    "    'L3_CO':['CO_column_number_density', 'H2O_column_number_density', 'cloud_height'],\n",
    "    'L3_AER_AI':['absorbing_aerosol_index']\n",
    "}\n",
    "\n",
    "def add_timeseries(df, dates, reducer=ee.Reducer.first()):\n",
    "    # Prepare dataframe with date x city\n",
    "    date_col = []\n",
    "    location_col = []\n",
    "    for d in dates:\n",
    "        for c in df.location.unique():\n",
    "            date_col.append(d)\n",
    "            location_col.append(c)\n",
    "\n",
    "    data = pd.DataFrame({\n",
    "        'Date':date_col,\n",
    "        'location':location_col\n",
    "    })\n",
    "    data = pd.merge(data, df[['location', 'Lat', 'Long']], how='left', on='location')\n",
    "    \n",
    "    for d in tqdm(dates):\n",
    "        # Weather is easy - a single image from the right date\n",
    "        weather_image = gfs.filter(ee.Filter.date(str(d.date()), str((d+timedelta(days=1)).date()))).first() # Filter to get the relevant image\n",
    "        # For the sentinel data, we get images from each collection and merge them\n",
    "        s5p_images = []\n",
    "        for COL in ['L3_NO2', 'L3_O3', 'L3_CO', 'L3_AER_AI']:\n",
    "            collection = S5p_collections[COL].filter(ee.Filter.date(str((d-timedelta(days=5)).date()), str(d.date())))\n",
    "            image = collection.qualityMosaic('system:time_start') # The most recent image\n",
    "            image = image.select(s5p_props[COL])\n",
    "            s5p_images.append(image)\n",
    "        s5p_image = ee.ImageCollection(s5p_images).toBands() # Merge into one image\n",
    "    \n",
    "        # Sample the weather data\n",
    "        samples = sample(weather_image, '', df['Lat'].values, df['Long'].values, reducer=reducer)\n",
    "        for prop in samples[0].keys():\n",
    "            data.loc[data.Date==d, prop] = [p[prop] for p in samples]\n",
    "            \n",
    "        # Sample the sentinel data\n",
    "        samples = sample(s5p_image, '', df['Lat'].values, df['Long'].values)\n",
    "        for prop in samples[0].keys():\n",
    "            data.loc[data.Date==d, prop] = [p[prop] for p in samples]\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "dates = pd.date_range('2020-01-01', '2020-01-04', freq='1D')\n",
    "add_timeseries(world.head(5).copy(), dates) # Show the result on the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-11-22'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world['Date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-31'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world['Date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96195, 7)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weather data is until 2020-11-30\n",
    "dates_2018 = pd.date_range('2018-11-22', '2018-12-31', freq='1D')\n",
    "dates_2019 = pd.date_range('2019-01-01', '2019-12-31', freq='1D')\n",
    "dates_2020 = pd.date_range('2020-01-01', '2020-12-31', freq='1D')\n",
    "dates_2021 = pd.date_range('2021-01-01', '2021-01-31', freq='1D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/02_OpenAQ/Colombia.csv')\n",
    "EC = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/02_OpenAQ/Ecuador.csv')\n",
    "PE = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/02_OpenAQ/Peru.csv')\n",
    "MX = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/02_OpenAQ/Mexico.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_data(data):\n",
    "    data = data.rename(columns={\"date.utc\": \"Date\", \"coordinates.latitude\": \"Lat\", \n",
    "                                 \"coordinates.longitude\":\"Long\", \"value\": \"PM25\"})\n",
    "    data['Date'] = data['Date'].astype(str).str[:10]\n",
    "    data = data.drop(columns=['unit', 'parameter'], axis =1)\n",
    "    data = data[['location', 'Date', 'city', 'country', 'PM25', 'Lat','Long']]\n",
    "    data['PM25'] = data.groupby(['Date','location'])['PM25'].transform(lambda x: x.mean())\n",
    "    data = data.groupby(['Date', 'location']).first().reset_index()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CO = trans_data(CO)\n",
    "EC = trans_data(EC)\n",
    "PE = trans_data(PE)\n",
    "MX = trans_data(MX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 9)\n",
      "(4087, 9)\n",
      "(42828, 9)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(331806, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(CO.shape)\n",
    "print(EC.shape)\n",
    "print(PE.shape)\n",
    "MX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data because it doesn't run in GEE when it's too large\n",
    "CO_1 = CO.iloc[:5000,:] \n",
    "CO_2 = CO.iloc[5001:8696,:]\n",
    "MX_1 = MX.iloc[:4000,:] \n",
    "MX_2 = MX.iloc[4001:8000,:]\n",
    "MX_3 = MX.iloc[8001:12000, :]\n",
    "MX_4 = MX.iloc[12001:16374, :]\n",
    "world_1 = world.iloc[:5000,:] \n",
    "world_2 = world.iloc[5001:10000,:]\n",
    "world_3 = world.iloc[10001:15000, :]\n",
    "world_4 = world.iloc[15001:20000, :]\n",
    "world_5 = world.iloc[20001:25000, :]\n",
    "world_6 = world.iloc[25001:30000, :]\n",
    "world_7 = world.iloc[30001:35000, :]\n",
    "world_8 = world.iloc[35001:40000,:]\n",
    "world_9 = world.iloc[40001:45000, :]\n",
    "world_10 = world.iloc[45001:50000, :]\n",
    "world_11 = world.iloc[50001:55000, :]\n",
    "world_12 = world.iloc[55001:60000, :]\n",
    "world_13 = world.iloc[60001:62482, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [12:14<00:00, 18.35s/it]\n"
     ]
    }
   ],
   "source": [
    "# Get the timeseries data\n",
    "ts_CO1 = add_timeseries(CO_1.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 365/365 [1:30:21<00:00, 14.85s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO2 = add_timeseries(CO_1.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 366/366 [1:22:48<00:00, 13.57s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO3 = add_timeseries(CO_1.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [05:25<00:00, 10.51s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO4 = add_timeseries(CO_1.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [06:18<00:00,  9.45s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO5 = add_timeseries(CO_2.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 365/365 [1:04:02<00:00, 10.53s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO6 = add_timeseries(CO_2.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 366/366 [1:01:52<00:00, 10.14s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO7 = add_timeseries(CO_2.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [04:57<00:00,  9.61s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_CO8 = add_timeseries(CO_2.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [01:23<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_EC1 = add_timeseries(EC.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 365/365 [12:52<00:00,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_EC2 = add_timeseries(EC.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 366/366 [12:39<00:00,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_EC3 = add_timeseries(EC.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [01:02<00:00,  2.02s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_EC4 = add_timeseries(EC.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [03:24<00:00,  5.12s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_PE1 = add_timeseries(PE.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 365/365 [34:30<00:00,  5.67s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_PE2 = add_timeseries(PE.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 366/366 [33:20<00:00,  5.46s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_PE3 = add_timeseries(PE.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [02:32<00:00,  4.92s/it]\n"
     ]
    }
   ],
   "source": [
    "ts_PE4 = add_timeseries(PE.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX1 = add_timeseries(MX_1.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX2 = add_timeseries(MX_1.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX3 = add_timeseries(MX_1.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX4 = add_timeseries(MX_1.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX5 = add_timeseries(MX_2.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX6 = add_timeseries(MX_2.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX7 = add_timeseries(MX_2.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX8 = add_timeseries(MX_2.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX9 = add_timeseries(MX_3.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX10 = add_timeseries(MX_3.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX11 = add_timeseries(MX_3.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX12 = add_timeseries(MX_3.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX13 = add_timeseries(MX_4.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX14 = add_timeseries(MX_4.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX15 = add_timeseries(MX_4.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_MX16 = add_timeseries(MX_4.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts1 = add_timeseries(world_1.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts2 = add_timeseries(world_1.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ts3 = add_timeseries(world_1.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts4 = add_timeseries(world_1.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts5 = add_timeseries(world_2.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts6 = add_timeseries(world_2.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts7 = add_timeseries(world_2.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts8 = add_timeseries(world_2.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts9 = add_timeseries(world_3.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts10 = add_timeseries(world_3.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts11 = add_timeseries(world_3.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts12 = add_timeseries(world_3.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts13 = add_timeseries(world_4.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts14 = add_timeseries(world_4.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts15 = add_timeseries(world_4.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts16 = add_timeseries(world_4.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts17 = add_timeseries(world_5.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts18 = add_timeseries(world_5.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts19 = add_timeseries(world_5.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts20 = add_timeseries(world_5.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts21 = add_timeseries(world_6.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts22 = add_timeseries(world_6.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts23 = add_timeseries(world_6.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts24 = add_timeseries(world_6.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts25 = add_timeseries(world_7.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts26 = add_timeseries(world_7.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts27 = add_timeseries(world_7.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts28 = add_timeseries(world_7.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts29 = add_timeseries(world_8.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts30 = add_timeseries(world_8.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts31 = add_timeseries(world_8.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts32 = add_timeseries(world_8.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts33 = add_timeseries(world_9.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts34 = add_timeseries(world_9.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts35 = add_timeseries(world_9.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts36 = add_timeseries(world_9.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts37 = add_timeseries(world_10.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts38 = add_timeseries(world_10.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts39 = add_timeseries(world_10.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts40 = add_timeseries(world_10.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts41 = add_timeseries(world_11.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts42 = add_timeseries(world_11.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts43 = add_timeseries(world_11.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts44 = add_timeseries(world_11.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts46 = add_timeseries(world_12.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts47 = add_timeseries(world_12.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts48 = add_timeseries(world_12.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts49 = add_timeseries(world_13.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts50 = add_timeseries(world_13.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts51 = add_timeseries(world_13.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts52 = add_timeseries(world_13.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT1 = add_timeseries(PT_1.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT2 = add_timeseries(PT_1.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT3 = add_timeseries(PT_1.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT4 = add_timeseries(PT_1.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT5 = add_timeseries(PT_2.copy(), dates_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT6 = add_timeseries(PT_2.copy(), dates_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT7 = add_timeseries(PT_2.copy(), dates_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT8 = add_timeseries(PT_2.copy(), dates_2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PT8.to_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/PT8.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NDVI (vegetation index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add vegetation index\n",
    "def add_static_vars2(df, scale = 8000):\n",
    "    vegs = ee.ImageCollection(\"NOAA/CDR/AVHRR/NDVI/V5\").filter(ee.Filter.date('2018-11-22', '2021-01-31')).first()\n",
    "    veg_list = [vegs]\n",
    "\n",
    "    for veg in tqdm(veg_list):\n",
    "        for i, reducer in enumerate([ee.Reducer.mean(), ee.Reducer.min(), ee.Reducer.max()]):\n",
    "            sampled_values = sample(veg, '', df['Lat'].values, df['Long'].values, reducer=reducer, scale=scale)\n",
    "            for k in sampled_values[0].keys():\n",
    "                arr = ['mean', 'min', 'max']\n",
    "                df[k+'_'+str(scale)+'_' + arr[i]] = [sv[k] if k in sv.keys() else None for sv in sampled_values]\n",
    "                if k == arr[i]:\n",
    "                    df = df.rename(columns={k+'_'+str(scale)+'_' + arr[i]:'veg_index'+'_'+str(scale)+'_' + arr[i]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "#dates = pd.date_range('2020-01-01', '2020-01-04', freq='1D')\n",
    "add_static_vars2(locations.head(5).copy()) # Show the result on the first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.02s/it]\n"
     ]
    }
   ],
   "source": [
    "# Add static vars\n",
    "locations_w_veg = add_static_vars2(locations.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_w_veg = locations_w_veg.drop(columns=['Date', 'PM25', 'Lat', 'Long', 'city','country'], axis=1)\n",
    "world_w_veg = pd.merge(world, locations_w_veg, on='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                       0\n",
       "location                   0\n",
       "city                    4163\n",
       "country                    0\n",
       "PM25                       0\n",
       "Lat                        0\n",
       "Long                       0\n",
       "NDVI_8500_mean         10013\n",
       "QA_8500_mean               0\n",
       "TIMEOFDAY_8500_mean     5983\n",
       "NDVI_8500_min          14139\n",
       "QA_8500_min                0\n",
       "TIMEOFDAY_8500_min      8332\n",
       "NDVI_8500_max          14139\n",
       "QA_8500_max                0\n",
       "TIMEOFDAY_8500_max      8332\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_w_veg.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elevation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_static_vars3(df, scale = 2000):\n",
    "    elevations = ee.Image('USGS/GMTED2010').select('be75')\n",
    "    elevation_list = [elevations]\n",
    "\n",
    "    for elevation in tqdm(elevation_list):\n",
    "        for i, reducer in enumerate([ee.Reducer.mean(), ee.Reducer.min(), ee.Reducer.max()]):\n",
    "            sampled_values = sample(elevation, '', df['Lat'].values, df['Long'].values, reducer=reducer, scale=scale)\n",
    "            for k in sampled_values[0].keys():\n",
    "                arr = ['mean', 'min', 'max']\n",
    "                df[k+'_'+str(scale)+'_' + arr[i]] = [sv[k] if k in sv.keys() else None for sv in sampled_values]\n",
    "                if k == arr[i]:\n",
    "                    df = df.rename(columns={k+'_'+str(scale)+'_' + arr[i]:'elevation'+'_'+str(scale)+'_' + arr[i]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:07<00:00,  7.50s/it]\n"
     ]
    }
   ],
   "source": [
    "locations_w_elevation = add_static_vars3(locations.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations_w_elevation = locations_w_elevation.drop(columns=['Date', 'PM25', 'Lat', 'Long', 'city','country'], axis=1)\n",
    "world_w_elevation = pd.merge(world, locations_w_elevation, on='location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date                     0\n",
       "location                 0\n",
       "city                  4163\n",
       "country                  0\n",
       "PM25                     0\n",
       "Lat                      0\n",
       "Long                     0\n",
       "elevation_500_mean      66\n",
       "elevation_500_min       66\n",
       "elevation_500_max       66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world_w_elevation.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human modification index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "final3 = pd.read_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/final3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "final3_locations = final3.groupby('location').first().reset_index() # The locations to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'first': 0.6889050602912903}]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = ee.ImageCollection(\"CSP/HM/GlobalHumanModification\").first()\n",
    "test = sample(image, '', [-18.136], [30.15], scale=1000) # See image value for a single location\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSP gHM: Global Human Modification\n",
    "def add_static_vars4(df, scale = 100):\n",
    "    lands = ee.ImageCollection(\"CSP/HM/GlobalHumanModification\").first()\n",
    "    land_list = [lands]\n",
    "\n",
    "    for land in tqdm(land_list):\n",
    "        for i, reducer in enumerate([ee.Reducer.mean(), ee.Reducer.min(), ee.Reducer.max()]):\n",
    "            sampled_values = sample(land, '', df['Lat'].values, df['Long'].values, reducer=reducer, scale=scale)\n",
    "            for k in sampled_values[0].keys():\n",
    "                arr = ['mean', 'min', 'max']\n",
    "                df[k+'_'+str(scale)+'_' + arr[i]] = [sv[k] if k in sv.keys() else None for sv in sampled_values]\n",
    "                if k == arr[i]:\n",
    "                    df = df.rename(columns={k+'_'+str(scale)+'_' + arr[i]:'Human_modification'+'_'+str(scale)+'_' + arr[i]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:03<00:00,  3.06s/it]\n"
     ]
    }
   ],
   "source": [
    "final3_w_add_static = add_static_vars4(final3_locations, scale = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>Date</th>\n",
       "      <th>location_ID</th>\n",
       "      <th>Lat_x</th>\n",
       "      <th>Long_x</th>\n",
       "      <th>Precipitable_water</th>\n",
       "      <th>RH</th>\n",
       "      <th>SH</th>\n",
       "      <th>Temp</th>\n",
       "      <th>U_wind</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI_8500_mean</th>\n",
       "      <th>QA_8500_mean</th>\n",
       "      <th>elevation_500_mean</th>\n",
       "      <th>PM25</th>\n",
       "      <th>mean_100_mean</th>\n",
       "      <th>mean_200_mean</th>\n",
       "      <th>Human_modification_500_mean</th>\n",
       "      <th>mean_1000_mean</th>\n",
       "      <th>Human_modification_500_min</th>\n",
       "      <th>Human_modification_500_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Borivali East, Mumbai - MPCB</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>38</td>\n",
       "      <td>19.132760</td>\n",
       "      <td>72.520480</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>74.900002</td>\n",
       "      <td>0.01667</td>\n",
       "      <td>27.051385</td>\n",
       "      <td>0.533428</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.996818</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Ciudad Bolivar</td>\n",
       "      <td>2020-10-29</td>\n",
       "      <td>74</td>\n",
       "      <td>-74.166278</td>\n",
       "      <td>4.577806</td>\n",
       "      <td>28.898485</td>\n",
       "      <td>93.916666</td>\n",
       "      <td>0.01250</td>\n",
       "      <td>14.984855</td>\n",
       "      <td>0.008136</td>\n",
       "      <td>...</td>\n",
       "      <td>-146.826949</td>\n",
       "      <td>-32638.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.620220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Khindipada-Bhandup West, Mumbai - IITM</td>\n",
       "      <td>2020-12-16</td>\n",
       "      <td>180</td>\n",
       "      <td>19.099180</td>\n",
       "      <td>72.553390</td>\n",
       "      <td>30.800001</td>\n",
       "      <td>67.400002</td>\n",
       "      <td>0.01380</td>\n",
       "      <td>25.694421</td>\n",
       "      <td>-2.181769</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>867.213000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   location        Date  location_ID  \\\n",
       "37             Borivali East, Mumbai - MPCB  2020-04-05           38   \n",
       "73                           Ciudad Bolivar  2020-10-29           74   \n",
       "179  Khindipada-Bhandup West, Mumbai - IITM  2020-12-16          180   \n",
       "\n",
       "         Lat_x     Long_x  Precipitable_water         RH       SH       Temp  \\\n",
       "37   19.132760  72.520480           21.600000  74.900002  0.01667  27.051385   \n",
       "73  -74.166278   4.577806           28.898485  93.916666  0.01250  14.984855   \n",
       "179  19.099180  72.553390           30.800001  67.400002  0.01380  25.694421   \n",
       "\n",
       "       U_wind  ...  NDVI_8500_mean  QA_8500_mean  elevation_500_mean  \\\n",
       "37   0.533428  ...             NaN         138.0                 0.0   \n",
       "73   0.008136  ...     -146.826949      -32638.0                 NaN   \n",
       "179 -2.181769  ...             NaN         138.0                 0.0   \n",
       "\n",
       "           PM25  mean_100_mean  mean_200_mean  Human_modification_500_mean  \\\n",
       "37    20.996818            NaN            NaN                          NaN   \n",
       "73    21.620220            NaN            NaN                          NaN   \n",
       "179  867.213000            NaN            NaN                          NaN   \n",
       "\n",
       "     mean_1000_mean  Human_modification_500_min  Human_modification_500_max  \n",
       "37              NaN                         NaN                         NaN  \n",
       "73              NaN                         NaN                         NaN  \n",
       "179             NaN                         NaN                         NaN  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final3_w_add_static.loc[final3_w_add_static['Human_modification_500_mean'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>location</th>\n",
       "      <th>location_ID</th>\n",
       "      <th>Lat_x</th>\n",
       "      <th>Long_x</th>\n",
       "      <th>Precipitable_water</th>\n",
       "      <th>RH</th>\n",
       "      <th>SH</th>\n",
       "      <th>Temp</th>\n",
       "      <th>U_wind</th>\n",
       "      <th>...</th>\n",
       "      <th>H2O</th>\n",
       "      <th>Cloud</th>\n",
       "      <th>Aerosol</th>\n",
       "      <th>avg_vis_mean</th>\n",
       "      <th>cf_cvg_mean</th>\n",
       "      <th>pop_density2010_mean</th>\n",
       "      <th>NDVI_8500_mean</th>\n",
       "      <th>QA_8500_mean</th>\n",
       "      <th>elevation_500_mean</th>\n",
       "      <th>PM25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-22</td>\n",
       "      <td>Camarones</td>\n",
       "      <td>53</td>\n",
       "      <td>19.4684</td>\n",
       "      <td>-99.1697</td>\n",
       "      <td>14.347721</td>\n",
       "      <td>39.937691</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>18.561679</td>\n",
       "      <td>0.085962</td>\n",
       "      <td>...</td>\n",
       "      <td>725.669616</td>\n",
       "      <td>558.024486</td>\n",
       "      <td>-0.609685</td>\n",
       "      <td>577.686646</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15686.94043</td>\n",
       "      <td>599.949881</td>\n",
       "      <td>24101.77088</td>\n",
       "      <td>2244.655991</td>\n",
       "      <td>34.095238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   location  location_ID    Lat_x   Long_x  Precipitable_water  \\\n",
       "0  2018-11-22  Camarones           53  19.4684 -99.1697           14.347721   \n",
       "\n",
       "          RH        SH       Temp    U_wind  ...         H2O       Cloud  \\\n",
       "0  39.937691  0.006379  18.561679  0.085962  ...  725.669616  558.024486   \n",
       "\n",
       "    Aerosol  avg_vis_mean  cf_cvg_mean  pop_density2010_mean  NDVI_8500_mean  \\\n",
       "0 -0.609685    577.686646          9.0           15686.94043      599.949881   \n",
       "\n",
       "   QA_8500_mean  elevation_500_mean       PM25  \n",
       "0   24101.77088         2244.655991  34.095238  \n",
       "\n",
       "[1 rows x 28 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "final4 = pd.merge(left =final3, right = final3_w_add_static, on = 'location_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date_x', 'location_x', 'location_ID', 'Lat_x_x', 'Long_x_x',\n",
       "       'Precipitable_water_x', 'RH_x', 'SH_x', 'Temp_x', 'U_wind_x',\n",
       "       'V_wind_x', 'NO2_column_x', 'NO2_slant_x', 'NO2_strato_x', 'Pressure_x',\n",
       "       'NO2_trop_x', 'O3_x', 'CO_x', 'H2O_x', 'Cloud_x', 'Aerosol_x',\n",
       "       'avg_vis_mean_x', 'cf_cvg_mean_x', 'pop_density2010_mean_x',\n",
       "       'NDVI_8500_mean_x', 'QA_8500_mean_x', 'elevation_500_mean_x', 'PM25_x',\n",
       "       'location_y', 'Date_y', 'Lat_x_y', 'Long_x_y', 'Precipitable_water_y',\n",
       "       'RH_y', 'SH_y', 'Temp_y', 'U_wind_y', 'V_wind_y', 'NO2_column_y',\n",
       "       'NO2_slant_y', 'NO2_strato_y', 'Pressure_y', 'NO2_trop_y', 'O3_y',\n",
       "       'CO_y', 'H2O_y', 'Cloud_y', 'Aerosol_y', 'avg_vis_mean_y',\n",
       "       'cf_cvg_mean_y', 'pop_density2010_mean_y', 'NDVI_8500_mean_y',\n",
       "       'QA_8500_mean_y', 'elevation_500_mean_y', 'PM25_y', 'mean_100_mean',\n",
       "       'mean_200_mean', 'Human_modification_500_mean', 'mean_1000_mean',\n",
       "       'Human_modification_500_min', 'Human_modification_500_max'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "final5 = final4.copy().drop(columns = ['Lat_x_x', 'Long_x_x','location_y', 'Date_y', 'Lat_x_y', 'Long_x_y', \n",
    "                                       'Precipitable_water_y',\n",
    "       'RH_y', 'SH_y', 'Temp_y', 'U_wind_y', 'V_wind_y', 'NO2_column_y',\n",
    "       'NO2_slant_y', 'NO2_strato_y', 'Pressure_y', 'NO2_trop_y', 'O3_y',\n",
    "       'CO_y', 'H2O_y', 'Cloud_y', 'Aerosol_y', 'avg_vis_mean_y',\n",
    "       'cf_cvg_mean_y', 'pop_density2010_mean_y', 'NDVI_8500_mean_y',\n",
    "       'QA_8500_mean_y', 'elevation_500_mean_y', 'PM25_y', 'mean_100_mean',\n",
    "       'mean_200_mean', 'mean_1000_mean',\n",
    "       'Human_modification_500_min', 'Human_modification_500_max'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "final5.to_csv('C:/Users/ayako/Documents/Berkeley Public Health/MPH Capstone_Air pollution and ARI/05_PM2.5 Prediction/final5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
